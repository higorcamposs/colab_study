{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Stable Baselines3 - Training, Saving and Loading\n",
        "\n",
        "Github Repo: [https://github.com/DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3)\n",
        "\n",
        "\n",
        "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a training framework for Reinforcement Learning (RL), using Stable Baselines3.\n",
        "\n",
        "It provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n",
        "\n",
        "Documentation is available online: [https://stable-baselines3.readthedocs.io/](https://stable-baselines3.readthedocs.io/)\n",
        "\n",
        "## Install Dependencies and Stable Baselines Using Pip\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines3[extra]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "id": "f6MW696s7DSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install swig cmake"
      ],
      "metadata": {
        "id": "cYMThnHPBEUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWskDE2c9WoN"
      },
      "outputs": [],
      "source": [
        "#!apt-get update && apt-get install swig cmake > \\dev/null\n",
        "#!pip install -q box2d-py\n",
        "#!pip install \"stable-baselines3[extra]\" #>=2.0.0a4\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[box2d]"
      ],
      "metadata": {
        "id": "zTqZaKFM74GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "id": "vHwvolGt6eJH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_ZkXrY-uLzX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"CarRacing-v2\", domain_randomize=True)\n",
        "\n",
        "# normal reset, this changes the colour scheme by default\n",
        "env.reset()\n",
        "\n",
        "# reset with colour scheme change\n",
        "env.reset(options={\"randomize\": True})\n",
        "\n",
        "# reset with no colour scheme change\n",
        "env.reset(options={\"randomize\": False})"
      ],
      "metadata": {
        "id": "dOHqUy2E7tti",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzG5f3qa5-Ae"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"CarRacing-v2\", domain_randomize=True)\n",
        "\n",
        "# normal reset, this changes the colour scheme by default\n",
        "env.reset()\n",
        "\n",
        "# reset with colour scheme change\n",
        "#env.reset(options={\"randomize\": True})\n",
        "\n",
        "# reset with no colour scheme change\n",
        "#env.reset(options={\"randomize\": False})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tckB9zYQ305U"
      },
      "outputs": [],
      "source": [
        "# for autoformatting\n",
        "# %load_ext jupyter_black"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Import policy, RL agent, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIedd7Pz9sOs"
      },
      "outputs": [],
      "source": [
        "# import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "from stable_baselines3 import DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RapkYvTXL7Cd"
      },
      "source": [
        "## Create the Gym env and instantiate the agent\n",
        "\n",
        "For this example, we will use Lunar Lander environment.\n",
        "\n",
        "\"Landing outside landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land on its first attempt. Four discrete actions available: do nothing, fire left orientation engine, fire main engine, fire right orientation engine. \"\n",
        "\n",
        "Lunar Lander environment: [https://gymnasium.farama.org/environments/box2d/lunar_lander/](https://gymnasium.farama.org/environments/box2d/lunar_lander/)\n",
        "\n",
        "![Lunar Lander](https://cdn-images-1.medium.com/max/960/1*f4VZPKOI0PYNWiwt0la0Rg.gif)\n",
        "\n",
        "\n",
        "We chose the MlpPolicy because input of Lunar Lander is a feature vector, not images.\n",
        "\n",
        "The type of action to use (discrete/continuous) will be automatically deduced from the environment action space\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgJ1QTBgbzyo"
      },
      "outputs": [],
      "source": [
        "# del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUWGZp3i9wyf"
      },
      "outputs": [],
      "source": [
        "model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    \"LunarLander-v2\",\n",
        "    verbose=1,\n",
        "    exploration_final_eps=0.1,\n",
        "    target_update_interval=250,\n",
        "\n",
        "    learning_rate=0.001,\n",
        "    # buffer_size=50000,\n",
        "    # batch_size=64,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4efFdrQ7MBvl"
      },
      "source": [
        "We load a helper function to evaluate the agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeaVBGuJwK97"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjEVOIY8NVeK"
      },
      "source": [
        "Let's evaluate the un-trained agent, this should be a random agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDHLMA6NFk95"
      },
      "outputs": [],
      "source": [
        "# Separate env for evaluation\n",
        "eval_env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "# Random Agent, before training\n",
        "mean_reward, std_reward = evaluate_policy(\n",
        "    model,\n",
        "    eval_env,\n",
        "    n_eval_episodes=10,\n",
        "    deterministic=True,\n",
        ")\n",
        "\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5UoXTZPNdFE"
      },
      "source": [
        "## Train the agent and save it\n",
        "\n",
        "Warning: this may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21uwATfoAa-3"
      },
      "outputs": [],
      "source": [
        "#del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4cfSXIB-pTF"
      },
      "outputs": [],
      "source": [
        "# Train the agent\n",
        "model.learn(total_timesteps=int(1e5))\n",
        "# Save the agent\n",
        "model.save(\"dqn_lunar\")\n",
        "\n",
        "#del model  # delete trained model to demonstrate loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T31dZJYNrJwF"
      },
      "source": [
        "## Load the trained agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1ExgtyZrIA6"
      },
      "outputs": [],
      "source": [
        "#model = DQN.load(\"dqn_lunar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygl_gVmV_QP7"
      },
      "outputs": [],
      "source": [
        "# Evaluate the trained agent\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "### Prepare video recording"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "outputs": [],
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLzXxO8VMD6N"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "\n",
        "def show_videos(video_path=\"\", prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "    :param video_path: (str) Path to the folder containing videos\n",
        "    :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTRNUfulOGaF"
      },
      "source": [
        "We will record a video using the [VecVideoRecorder](https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html#vecvideorecorder) wrapper, you will learn about those wrapper in the next notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Trag9dQpOIhx"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "\n",
        "def record_video(env_id, model, video_length=100000, prefix=\"\", video_folder=\"videos/\"):\n",
        "    \"\"\"\n",
        "    :param env_id: (str)\n",
        "    :param model: (RL model)\n",
        "    :param video_length: (int)\n",
        "    :param prefix: (str)\n",
        "    :param video_folder: (str)\n",
        "    \"\"\"\n",
        "    eval_env = DummyVecEnv([lambda: gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")])\n",
        "    # Start the video at step=0 and record 500 steps\n",
        "    eval_env = VecVideoRecorder(\n",
        "        eval_env,\n",
        "        video_folder=video_folder,\n",
        "        record_video_trigger=lambda step: step == 0,\n",
        "        video_length=video_length,\n",
        "        name_prefix=prefix,\n",
        "    )\n",
        "\n",
        "    obs = eval_env.reset()\n",
        "    for _ in range(video_length):\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "    # Close the video recorder\n",
        "    eval_env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOObbeu5MMlR"
      },
      "source": [
        "### Visualize trained agent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iATu7AiyMQW2"
      },
      "outputs": [],
      "source": [
        "record_video(\"LunarLander-v2\", model, video_length=1000, prefix=\"ppo-lunarlander\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n4i-fW3NojZ"
      },
      "outputs": [],
      "source": [
        "show_videos(\"videos\", prefix=\"ppo\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "3201c96db5836b171d01fee72ea1be894646622d4b41771abf25c98b548a611d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}